{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import warnings\n",
    "import fiftyone as fo\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from fiftyone.types import COCODetectionDataset\n",
    "from fiftyone import ViewField as F\n",
    "warnings.filterwarnings('ignore')\n",
    "dataset_dir = \"/Users/adrienmonks/CS5990/FinalProject/fiftyone/coco-2017\"\n",
    "\n",
    "train_dir = f\"{dataset_dir}/train2017\"\n",
    "val_dir = f\"{dataset_dir}/val2017\"\n",
    "test_dir = f\"{dataset_dir}/test2017\"\n",
    "annotations_dir = f\"{dataset_dir}/annotations/annotations\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-05T02:54:25.254279Z",
     "start_time": "2024-12-05T02:54:17.692660Z"
    }
   },
   "id": "fb3873f494f1372e",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(f\"{annotations_dir}/instances_train2017.json\", \"r\") as f:\n",
    "    annotations = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-05T02:36:54.288146Z",
     "start_time": "2024-12-05T02:35:11.584605Z"
    }
   },
   "id": "ab5532d9890da080",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"loading train dataset...\")\n",
    "train_dataset = fo.Dataset.from_dir(\n",
    "    dataset_type=COCODetectionDataset,\n",
    "    data_path=train_dir,\n",
    "    labels_path=f\"{annotations_dir}/instances_train2017.json\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0435753ad487146"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# saving training data\n",
    "train_dataset.name = \"train_dataset\" \n",
    "train_dataset.save()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T15:56:08.901186Z",
     "start_time": "2024-11-19T15:56:08.861734Z"
    }
   },
   "id": "6776ce58b15bd4c8",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"Loading train dataset from saved state...\")\n",
    "train_dataset = fo.load_dataset(\"train_dataset\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8f83ebe2afebf53"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"loading val dataset...\")\n",
    "val_dataset = fo.Dataset.from_dir(\n",
    "    dataset_type=COCODetectionDataset,\n",
    "    data_path=val_dir,\n",
    "    labels_path=f\"{annotations_dir}/instances_val2017.json\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "216efe1dbc3ec381"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "val_dataset.name = \"val_dataset\"\n",
    "val_dataset.save()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53c18421ad0a6eb1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading val dataset from saved state...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading val dataset from saved state...\")\n",
    "val_dataset = fo.load_dataset(\"val_dataset\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-03T17:16:13.841400Z",
     "start_time": "2024-12-03T17:16:13.814056Z"
    }
   },
   "id": "e069773520822a74",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"loading test dataset...\")\n",
    "test_dataset = fo.Dataset.from_dir(\n",
    "    dataset_type=COCODetectionDataset,\n",
    "    data_path=test_dir,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98efb97e7f932082"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#filter by animals \n",
    "\n",
    "train_animal_images = train_dataset.filter_labels(\"detections\", F(\"supercategory\") == \"animal\")\n",
    "val_animal_images = val_dataset.filter_labels(\"detections\", F(\"supercategory\") == \"animal\")\n",
    "\n",
    "print(len(train_animal_images))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87ce527887e8c762"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_animal_images = test_dataset.filter_labels(\"detections\", F(\"supercategory\") == \"animal\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f369a6098411c55c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118287\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-01T22:59:41.219188Z",
     "start_time": "2024-12-01T22:59:41.110311Z"
    }
   },
   "id": "6e4771481703bdf1",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.lib.display.IFrame at 0x14852ba90>",
      "text/html": "\n        <iframe\n            width=\"100%\"\n            height=\"800\"\n            src=\"http://localhost:5151/?notebook=True&subscription=bc21726c-c591-473d-9170-8610308cbd8a\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#launch fiftyone session \n",
    "session = fo.launch_app(train_animal_images)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T01:38:40.127818Z",
     "start_time": "2024-12-04T01:38:35.948238Z"
    }
   },
   "id": "3f247e772a44a854",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "session.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-03T19:44:52.250532Z",
     "start_time": "2024-12-03T19:44:47.760122Z"
    }
   },
   "id": "c13de66dee77f4e8",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Extract unique categories for animals from the filtered train dataset\n",
    "# Create unique labels from 'label' field\n",
    "unique_labels = list(\n",
    "    set(\n",
    "        detection[\"label\"]\n",
    "        for sample in train_animal_images.select_fields(\"detections\")\n",
    "        if sample[\"detections\"] is not None and \"detections\" in sample[\"detections\"] \n",
    "        for detection in sample[\"detections\"][\"detections\"]\n",
    "    )\n",
    ")\n",
    "num_classes = len(unique_labels)\n",
    "label_to_int = {label: idx for idx, label in enumerate(unique_labels)}  # Create mapping correctly \n",
    "\n",
    "\n",
    "# Convert COCO annotations for train, val datasets to NumPy-compatible structures\n",
    "def extract_images_and_labels(dataset, label_to_int):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for sample in dataset:\n",
    "        filepath = sample.filepath\n",
    "        # Ensure 'detections' exists and is not None - doesn't exist for a couple\n",
    "        if sample[\"detections\"] is None or \"detections\" not in sample[\"detections\"]:\n",
    "            continue\n",
    "\n",
    "        detections = sample[\"detections\"][\"detections\"]\n",
    "        if not detections:  # Skip samples with no detections\n",
    "            continue\n",
    "\n",
    "        for detection in detections:\n",
    "            label = detection[\"label\"] \n",
    "            if label in label_to_int:  # Only animals\n",
    "                image_paths.append(filepath)\n",
    "                labels.append(label_to_int[label])\n",
    "\n",
    "    return image_paths, labels\n",
    "\n",
    "\n",
    "print(\"Extracting train images and labels...\")\n",
    "train_images, train_labels = extract_images_and_labels(train_animal_images, label_to_int)\n",
    "\n",
    "print(\"Extracting val images and labels...\")\n",
    "val_images, val_labels = extract_images_and_labels(val_animal_images, label_to_int)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d42f3525e82c2393"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cow', 'zebra', 'horse', 'sheep', 'cat', 'bear', 'bird', 'elephant', 'giraffe', 'dog']\n"
     ]
    }
   ],
   "source": [
    "print(unique_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T03:08:07.306980Z",
     "start_time": "2024-12-02T03:08:07.295666Z"
    }
   },
   "id": "80cc5cb8400a1a48",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-30T19:23:09.116565Z",
     "start_time": "2024-11-30T19:23:09.112024Z"
    }
   },
   "id": "6cbb69ecc4c9f400",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21.5M/21.5M [00:01<00:00, 11.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "#model = YOLO('yolov8l.pt') # large\n",
    "#model = YOLO('yolov8x.pt') #extra large, most accurate, but slower\n",
    "model = YOLO(\"yolov8s.pt\") #small"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-30T19:35:08.058500Z",
     "start_time": "2024-11-30T19:35:05.022367Z"
    }
   },
   "id": "80ebc6339bbd6af4",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cow', 'zebra', 'horse', 'sheep', 'cat', 'bear', 'bird', 'elephant', 'giraffe', 'dog']\n"
     ]
    }
   ],
   "source": [
    "print(unique_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-01T23:16:59.866422Z",
     "start_time": "2024-12-01T23:16:59.825923Z"
    }
   },
   "id": "6ddffb1e1c05c4cd",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(f\"{annotations_dir}/instances_val2017.json\", \"r\") as f:\n",
    "    val_annotations = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-05T02:55:04.344213Z",
     "start_time": "2024-12-05T02:55:03.925255Z"
    }
   },
   "id": "256bc1251472a138",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing YOLO dataset at ./fiftyone/yolo-dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "yolo_dataset_dir = \"./fiftyone/yolo-dataset\"\n",
    "\n",
    "# Delete the directory\n",
    "if os.path.exists(yolo_dataset_dir):\n",
    "    shutil.rmtree(yolo_dataset_dir)\n",
    "    print(f\"Deleted existing YOLO dataset at {yolo_dataset_dir}\")\n",
    "else:\n",
    "    print(f\"No existing YOLO dataset found at {yolo_dataset_dir}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-01T23:24:32.312452Z",
     "start_time": "2024-12-01T23:24:25.838079Z"
    }
   },
   "id": "2044da8b7154f04c",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting train: 100%|██████████| 860001/860001 [00:06<00:00, 124543.44it/s]\n",
      "Converting val: 100%|██████████| 36781/36781 [00:00<00:00, 73729.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO dataset created successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "\n",
    "coco_dir = \"./fiftyone/coco-2017\" \n",
    "output_dir = \"./fiftyone/yolo-dataset\"  # Output directory for YOLO dataset\n",
    "\n",
    "import shutil\n",
    "\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)  # Delete the folder and its contents\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def convert_coco_to_yolo(annotations, image_dir, output_dir, subset_name, unique_labels):\n",
    "    \"\"\"\n",
    "    Converts COCO annotations to YOLO format and organizes the dataset structure.\n",
    "    \"\"\"\n",
    "    # Create directories for YOLO dataset\n",
    "    subset_img_dir = os.path.join(output_dir, subset_name, \"images\")\n",
    "    subset_lbl_dir = os.path.join(output_dir, subset_name, \"labels\")\n",
    "    os.makedirs(subset_img_dir, exist_ok=True)\n",
    "    os.makedirs(subset_lbl_dir, exist_ok=True)\n",
    "\n",
    "    # Mapping category IDs to YOLO class indices for unique_labels only\n",
    "    categories = annotations[\"categories\"]\n",
    "    cat_id_to_name = {cat[\"id\"]: cat[\"name\"] for cat in categories if cat[\"name\"] in unique_labels}\n",
    "    # Ensure the order of YOLO indices matches unique_labels\n",
    "    cat_id_to_yolo = {cat[\"id\"]: unique_labels.index(cat[\"name\"]) for cat in categories if cat[\"name\"] in unique_labels}\n",
    "        \n",
    "    # Map image IDs to filenames and dimensions\n",
    "    img_id_to_file = {img[\"id\"]: img[\"file_name\"] for img in annotations[\"images\"]}\n",
    "    img_id_to_dims = {img[\"id\"]: (img[\"width\"], img[\"height\"]) for img in annotations[\"images\"]}\n",
    "\n",
    "    valid_image_ids = set() \n",
    "\n",
    "    # Process annotations\n",
    "    for ann in tqdm(annotations[\"annotations\"], desc=f\"Converting {subset_name}\"):\n",
    "        img_id = ann[\"image_id\"]\n",
    "        category_id = ann[\"category_id\"]\n",
    "        bbox = ann[\"bbox\"]  # [x_min, y_min, width, height]\n",
    "\n",
    "        if category_id not in cat_id_to_yolo:\n",
    "            continue  # Skip non-relevant categories within image\n",
    "\n",
    "        # Get image dimensions\n",
    "        img_width, img_height = img_id_to_dims[img_id]\n",
    "        x_min, y_min, box_width, box_height = bbox\n",
    "        x_center = (x_min + box_width / 2) / img_width\n",
    "        y_center = (y_min + box_height / 2) / img_height\n",
    "        norm_width = box_width / img_width\n",
    "        norm_height = box_height / img_height\n",
    "\n",
    "        # Create YOLO label line\n",
    "        label_line = f\"{cat_id_to_yolo[category_id]} {x_center} {y_center} {norm_width} {norm_height}\\n\"\n",
    "\n",
    "        # Write label to corresponding .txt file\n",
    "        label_path = os.path.join(subset_lbl_dir, f\"{os.path.splitext(img_id_to_file[img_id])[0]}.txt\")\n",
    "        with open(label_path, \"a\") as f:\n",
    "            f.write(label_line)\n",
    "\n",
    "        # Mark this image as valid\n",
    "        valid_image_ids.add(img_id)\n",
    "\n",
    "    # Copy only valid images\n",
    "    for img_id in valid_image_ids:\n",
    "        src_img_path = os.path.join(image_dir, img_id_to_file[img_id])\n",
    "        dest_img_path = os.path.join(subset_img_dir, img_id_to_file[img_id])\n",
    "        if os.path.exists(src_img_path):\n",
    "            copyfile(src_img_path, dest_img_path)\n",
    "\n",
    "\n",
    "# Convert train and val datasets\n",
    "convert_coco_to_yolo(\n",
    "    annotations=annotations,\n",
    "    image_dir=os.path.join(coco_dir, \"train2017\"),\n",
    "    output_dir=output_dir,\n",
    "    subset_name=\"train\",\n",
    "    unique_labels=unique_labels\n",
    ")\n",
    "\n",
    "\n",
    "convert_coco_to_yolo(\n",
    "    annotations=val_annotations,\n",
    "    image_dir=os.path.join(coco_dir, \"val2017\"),\n",
    "    output_dir=output_dir,\n",
    "    subset_name=\"val\",\n",
    "    unique_labels=unique_labels\n",
    ")\n",
    "\n",
    "# Create data.yaml\n",
    "data_yaml_path = os.path.join(output_dir, \"data.yaml\")\n",
    "with open(data_yaml_path, \"w\") as f:\n",
    "    f.write(f\"train: {os.path.abspath(os.path.join(output_dir, 'train/images'))}\\n\")\n",
    "    f.write(f\"val: {os.path.abspath(os.path.join(output_dir, 'val/images'))}\\n\")\n",
    "    f.write(f\"nc: {len(unique_labels)}\\n\")\n",
    "    f.write(f\"names: {unique_labels}\\n\")\n",
    "\n",
    "print(\"YOLO dataset created successfully!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T03:58:51.344309Z",
     "start_time": "2024-12-02T03:58:20.664394Z"
    }
   },
   "id": "986d7bc167acf4d1",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories created: ./fiftyone/yolo-dataset/test/images, ./fiftyone/yolo-dataset/test/labels\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "\n",
    "output_dir = \"./fiftyone/yolo-dataset/test\"  # Output directory for YOLO-compatible test dataset\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create YOLO test dataset structure\n",
    "subset_img_dir = os.path.join(output_dir, \"images\")\n",
    "subset_lbl_dir = os.path.join(output_dir, \"labels\")\n",
    "os.makedirs(subset_img_dir, exist_ok=True)\n",
    "os.makedirs(subset_lbl_dir, exist_ok=True)\n",
    "\n",
    "# Ensure unique labels mapping exists\n",
    "# Replace with your actual mapping of categories to indices\n",
    "label_to_int = {label: idx for idx, label in enumerate(set(y_val_split))}\n",
    "\n",
    "# Convert `X_val_split` and `y_val_split` into YOLO format\n",
    "def convert_to_yolo_format(image_paths, labels, output_img_dir, output_lbl_dir, label_to_int):\n",
    "    for img_path, label in tqdm(zip(image_paths, labels), desc=\"Converting test set\", total=len(image_paths)):\n",
    "        # Copy the image to the test images directory\n",
    "        dest_img_path = os.path.join(output_img_dir, os.path.basename(img_path))\n",
    "        copyfile(img_path, dest_img_path)\n",
    "\n",
    "        # Generate the YOLO label file\n",
    "        label_file = os.path.join(output_lbl_dir, f\"{os.path.splitext(os.path.basename(img_path))[0]}.txt\")\n",
    "        \n",
    "        # If label includes bounding boxes, modify this block\n",
    "        with open(label_file, \"w\") as f:\n",
    "            if isinstance(label, list):  # Multiple detections\n",
    "                for bbox in label:\n",
    "                    # For bounding box labels, format as \"<class_id> <x_center> <y_center> <width> <height>\"\n",
    "                    f.write(\" \".join(map(str, bbox)) + \"\\n\")\n",
    "            else:  # Single detection (just class_id for now)\n",
    "                f.write(f\"{label_to_int[label]} 0.5 0.5 0.2 0.2\\n\")  # Placeholder bbox\n",
    "\n",
    "convert_to_yolo_format(\n",
    "    X_val_split, y_val_split, subset_img_dir, subset_lbl_dir, label_to_int\n",
    ")\n",
    "\n",
    "print(\"YOLO test dataset created successfully!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T22:05:26.478657Z",
     "start_time": "2024-12-04T22:05:26.448902Z"
    }
   },
   "id": "ce9cdbc359f3d812",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#2014 conversions\n",
    "dataset_dir2 = \"/Users/adrienmonks/CS5990/FinalProject/fiftyone/coco-2014\"\n",
    "with open(f\"{dataset_dir2}/annotations/instances_val2014.json\",\"r\") as f:\n",
    "    annotations2 = json.load(f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-05T02:56:09.753907Z",
     "start_time": "2024-12-05T02:56:06.896023Z"
    }
   },
   "id": "f3f46ce9039475fa",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(annotations2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-05T02:56:12.787057Z",
     "start_time": "2024-12-05T02:56:12.778173Z"
    }
   },
   "id": "afcdea4383989cf3",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading val dataset2...\n",
      " 100% |█████████████| 40504/40504 [14.6m elapsed, 0s remaining, 125.8 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "print(\"loading val dataset2...\")\n",
    "val_dataset2 = fo.Dataset.from_dir(\n",
    "    dataset_type=COCODetectionDataset,\n",
    "    data_path=\"/Users/adrienmonks/CS5990/FinalProject/fiftyone/coco-2014/val2014\",\n",
    "    labels_path=\"/Users/adrienmonks/CS5990/FinalProject/fiftyone/coco-2014/annotations/instances_val2014.json\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-05T02:33:11.876691Z",
     "start_time": "2024-12-05T02:18:28.950072Z"
    }
   },
   "id": "24f7fe66b27228f",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "val_dataset2.name = \"val_dataset2\"\n",
    "val_dataset2.save()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-05T02:33:55.383584Z",
     "start_time": "2024-12-05T02:33:55.318957Z"
    }
   },
   "id": "498dbf6ad54e1655",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading val2 dataset from saved state...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading val2 dataset from saved state...\")\n",
    "val_dataset2 = fo.load_dataset(\"val_dataset2\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-05T02:57:46.492740Z",
     "start_time": "2024-12-05T02:57:42.060365Z"
    }
   },
   "id": "6a0872746b897834",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8265\n"
     ]
    }
   ],
   "source": [
    "val_animal_images2 = val_dataset2.filter_labels(\"detections\", F(\"supercategory\") == \"animal\")\n",
    "print(len(val_animal_images2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-05T02:58:00.400149Z",
     "start_time": "2024-12-05T02:58:00.073542Z"
    }
   },
   "id": "b41027c8b4bdb247",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "unique_labels = ['cow', 'zebra', 'horse', 'sheep', 'cat', 'bear', 'bird', 'elephant', 'giraffe', 'dog']\n",
    "label_to_int = {label: idx for idx, label in enumerate(unique_labels)}  # Create mapping"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-05T03:06:04.494851Z",
     "start_time": "2024-12-05T03:06:04.486977Z"
    }
   },
   "id": "337255761e204d8c",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Convert COCO annotations \n",
    "def extract_images_and_labels(dataset, label_to_int):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for sample in dataset:\n",
    "        filepath = sample.filepath\n",
    "        # Ensure 'detections' exists and is not None\n",
    "        if sample[\"detections\"] is None or \"detections\" not in sample[\"detections\"]:\n",
    "            continue\n",
    "\n",
    "        detections = sample[\"detections\"][\"detections\"]\n",
    "        if not detections:  # Skip samples with no detections\n",
    "            continue\n",
    "\n",
    "        for detection in detections:\n",
    "            label = detection[\"label\"]  # Use the 'label' field for class names\n",
    "            if label in label_to_int:  # Filter relevant categories\n",
    "                image_paths.append(filepath)\n",
    "                labels.append(label_to_int[label])\n",
    "\n",
    "    return image_paths, labels\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-05T03:06:22.338552Z",
     "start_time": "2024-12-05T03:06:22.333702Z"
    }
   },
   "id": "6151217279f3c9f3",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "val_images2, val_labels2 = extract_images_and_labels(val_animal_images2, label_to_int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-05T03:06:40.744736Z",
     "start_time": "2024-12-05T03:06:27.205872Z"
    }
   },
   "id": "f3a125bbbe89f7b7",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting test: 100%|██████████| 291875/291875 [00:01<00:00, 182346.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO dataset created successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "\n",
    "# Paths relative to FinalProject\n",
    "coco_dir = \"./fiftyone/coco-2014\"  # Your COCO dataset root directory\n",
    "output_dir = \"./fiftyone/yolo-dataset-test\"  # Output directory for YOLO dataset\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Clean the dataset directory\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)  # Delete the folder and its contents\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def convert_coco_to_yolo(annotations, image_dir, output_dir, subset_name, unique_labels):\n",
    "    \"\"\"\n",
    "    Converts COCO annotations to YOLO format and organizes the dataset structure.\n",
    "    \"\"\"\n",
    "    # Create directories for YOLO dataset\n",
    "    subset_img_dir = os.path.join(output_dir, subset_name, \"images\")\n",
    "    subset_lbl_dir = os.path.join(output_dir, subset_name, \"labels\")\n",
    "    os.makedirs(subset_img_dir, exist_ok=True)\n",
    "    os.makedirs(subset_lbl_dir, exist_ok=True)\n",
    "\n",
    "    # Mapping category IDs to YOLO class indices for unique_labels only\n",
    "    categories = annotations[\"categories\"]\n",
    "    cat_id_to_name = {cat[\"id\"]: cat[\"name\"] for cat in categories if cat[\"name\"] in unique_labels}\n",
    "    # Ensure the order of YOLO indices matches unique_labels\n",
    "    cat_id_to_yolo = {cat[\"id\"]: unique_labels.index(cat[\"name\"]) for cat in categories if cat[\"name\"] in unique_labels}\n",
    "        \n",
    "    # Map image IDs to filenames and dimensions\n",
    "    img_id_to_file = {img[\"id\"]: img[\"file_name\"] for img in annotations[\"images\"]}\n",
    "    img_id_to_dims = {img[\"id\"]: (img[\"width\"], img[\"height\"]) for img in annotations[\"images\"]}\n",
    "\n",
    "    valid_image_ids = set()  # Track images with valid annotations\n",
    "\n",
    "    # Process annotations\n",
    "    for ann in tqdm(annotations[\"annotations\"], desc=f\"Converting {subset_name}\"):\n",
    "        img_id = ann[\"image_id\"]\n",
    "        category_id = ann[\"category_id\"]\n",
    "        bbox = ann[\"bbox\"]  # [x_min, y_min, width, height]\n",
    "\n",
    "        if category_id not in cat_id_to_yolo:\n",
    "            continue  # Skip non-relevant categories\n",
    "\n",
    "        # Get image dimensions\n",
    "        img_width, img_height = img_id_to_dims[img_id]\n",
    "        x_min, y_min, box_width, box_height = bbox\n",
    "        x_center = (x_min + box_width / 2) / img_width\n",
    "        y_center = (y_min + box_height / 2) / img_height\n",
    "        norm_width = box_width / img_width\n",
    "        norm_height = box_height / img_height\n",
    "\n",
    "        # Create YOLO label line\n",
    "        label_line = f\"{cat_id_to_yolo[category_id]} {x_center} {y_center} {norm_width} {norm_height}\\n\"\n",
    "\n",
    "        # Write label to corresponding .txt file\n",
    "        label_path = os.path.join(subset_lbl_dir, f\"{os.path.splitext(img_id_to_file[img_id])[0]}.txt\")\n",
    "        with open(label_path, \"a\") as f:\n",
    "            f.write(label_line)\n",
    "\n",
    "        # Mark this image as valid\n",
    "        valid_image_ids.add(img_id)\n",
    "\n",
    "    # Copy only valid images\n",
    "    for img_id in valid_image_ids:\n",
    "        src_img_path = os.path.join(image_dir, img_id_to_file[img_id])\n",
    "        dest_img_path = os.path.join(subset_img_dir, img_id_to_file[img_id])\n",
    "        if os.path.exists(src_img_path):\n",
    "            copyfile(src_img_path, dest_img_path)\n",
    "\n",
    "\n",
    "\n",
    "convert_coco_to_yolo(\n",
    "    annotations=annotations2,\n",
    "    image_dir=os.path.join(coco_dir, \"val2014\"),\n",
    "    output_dir=output_dir,\n",
    "    subset_name=\"test\",\n",
    "    unique_labels=unique_labels\n",
    ")\n",
    "\n",
    "# Create data.yaml\n",
    "data_yaml_path = os.path.join(output_dir, \"data.yaml\")\n",
    "with open(data_yaml_path, \"w\") as f:\n",
    "    f.write(f\"test: {os.path.abspath(os.path.join(output_dir, 'test/images'))}\\n\")\n",
    "    f.write(f\"nc: {len(unique_labels)}\\n\")\n",
    "    f.write(f\"names: {unique_labels}\\n\")\n",
    "\n",
    "print(\"YOLO dataset created successfully!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-05T03:07:00.762352Z",
     "start_time": "2024-12-05T03:06:53.470008Z"
    }
   },
   "id": "e5d0c2b58a5890cf",
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
